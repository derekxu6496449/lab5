---
title: "Lab-5"
author: "YangXu"
format:
  html:
    embed-resources: true
---

```{r, message=FALSE}
library(R.utils)
library(data.table)
library(leaflet)
library(tidyverse)
if (!file.exists("met_all.gz"))
  download.file(
    url = "https://raw.githubusercontent.com/USCbiostats/data-science-data/master/02_met/met_all.gz",
    destfile = "met_all.gz",
    method   = "libcurl",
    timeout  = 60
    )
met <- data.table::fread("met_all.gz")

# Download the data
stations <- fread("ftp://ftp.ncdc.noaa.gov/pub/data/noaa/isd-history.csv")
stations[, USAF := as.integer(USAF)]

# Dealing with NAs and 999999
stations[, USAF   := fifelse(USAF == 999999, NA_integer_, USAF)]
stations[, CTRY   := fifelse(CTRY == "", NA_character_, CTRY)]
stations[, STATE  := fifelse(STATE == "", NA_character_, STATE)]

# Selecting the three relevant columns, and keeping unique records
stations <- unique(stations[, list(USAF, CTRY, STATE)])

# Dropping NAs
stations <- stations[!is.na(USAF)]

# Removing duplicates
stations[, n := 1:.N, by = .(USAF)]
stations <- stations[n == 1,][, n := NULL]
```

Merge the data
```{r}
merge(
  # Data
  x     = met,      
  y     = stations, 
  # List of variables to match
  by.x  = "USAFID",
  by.y  = "USAF", 
  # Which obs to keep?
  all.x = TRUE,      
  all.y = FALSE
  ) %>% nrow()

dat <- merge(
  # Data
  x     = met,      
  y     = stations, 
  # List of variables to match
  by.x  = "USAFID",
  by.y  = "USAF", 
  # Which obs to keep?
  all.x = TRUE,      
  all.y = FALSE
  )
head(dat[, list(USAFID, WBAN, STATE)], n = 4)
```

Q1. Representative station in the US
```{r}
# Get the average temp, atm.press and wind.sp of each station
station_avg <- dat[,.(
  temp            = mean(temp,na.rm = TRUE),
  atm.press       = mean(atm.press,na.rm = TRUE),
  wind.sp         = mean(wind.sp,na.rm=TRUE),
  lat             = lat,
  lon.            = lon
),by = c("USAFID","STATE")]

# Get median temp, atm.press and wind.sp of the US
median_temp <- quantile(dat$temp, probs = 0.5, na.rm = TRUE)
median_atm.press <- quantile(dat$atm.press, probs = 0.5, na.rm = TRUE)
median_wind.sp <- quantile(dat$wind.sp,probs = 0.5, na.rm = TRUE)

# Find the stations whose temp, wind.sp and atm.press is closest to the median
# Temp
station_avg[, temp_dist := abs(temp - median_temp)]
station_avg <- station_avg[order(temp_dist)]
station_temp_median <- station_avg[order(temp_dist)][1]
station_temp_median

# atm.press
station_avg[, atm_dist := abs(atm.press - median_atm.press)]
station_avg <- station_avg[order(atm_dist)]
station_atm_median <- station_avg[order(atm_dist)][1]
station_atm_median

# wind.sp
station_avg[, wind_dist := abs(wind.sp - median_wind.sp)]
station_avg <- station_avg[order(wind_dist)]
station_wind_median <- station_avg[order(wind_dist)][1]
station_wind_median
```
```{r}
#These three stations do not coincide.
#Temp:             USAFID:725830    STATE: NV
#atm.press:        USAFID:725340    STATE: IL
#wind.sp:          USAFID:725479    STATE: IA
```

Q2. Representative station per state
```{r}
station_avg_state <- station_avg
station_avg_state[, temp_median := quantile(temp, probs = 0.5, na.rm = TRUE), by = STATE]
station_avg_state[, wind_median := quantile(wind.sp,probs = 0.5, na.rm = TRUE), by = STATE]
station_avg_state[, atm_median := quantile(atm.press, probs = 0.5, na.rm = TRUE), by = STATE]
station_avg_state[,eucd := sqrt((temp - temp_median)^2 + (wind.sp - wind_median)^2 + (atm.press - atm_median)^2), by = STATE]
median_stations <- station_avg_state %>%
  group_by(STATE) %>%
  arrange(eucd, lat)
min_station <- median_stations %>%
  group_by(STATE) %>%
  filter(lat == min(lat))
min_station <- min_station[!duplicated(min_station$USAFID),]
min_station
```

Above are the representative station per state.


Q3. In the middle?
```{r}
# Identify the closest
mid_lat <- median(dat$lat)
mid_lon <- median(dat$lon)
state_midpoints <- median_stations %>%
  group_by(STATE) %>%
  summarize(
    midpt_lat = median(lat),
    midpt_lon = median(lon.)
  )
closest_stations <- state_midpoints %>%
  rowwise() %>%
  mutate(
    closest_distance = min(sqrt((mid_lat - median_stations$lat)^2 + (mid_lon - median_stations$lon.)^2)))

# map
map <- leaflet() %>%
  addTiles() %>%
  addCircles(
    data = closest_stations,
    lng = ~midpt_lon,
    lat = ~midpt_lat,
    label = ~STATE,
    color = "blue"
  ) %>%
  addCircles(
    data = min_station,
    lng = ~lon.,
    lat = ~lat,
    label = ~STATE,
    color = "green"
  ) %>%
  addLegend(
    colors = c("green", "blue"),
    labels = c("Midpoints", "Medians"),
    title = "Locations",
    opacity = 1
  )
map
```


Q4. Means of means
```{r}
state_avg_temp <- dat %>%
  group_by(STATE) %>%
  summarize(mean_temp = mean(temp, na.rm = TRUE))

state_avg_temp <- state_avg_temp %>%
  mutate(
    avg_temp_level = case_when(
      mean_temp < 20 ~ "Low",
      mean_temp >= 20 & mean_temp < 25 ~ "Mid",
      mean_temp >= 25 ~ "High",
    )
  )

quantile(state_avg_temp$mean_temp)

# merge two tables
dat_avgtemp <- merge(dat,state_avg_temp, by = "STATE", all.x = TRUE)

# Summary by temperature category
Table <- dat_avgtemp %>%
  group_by(avg_temp_level) %>%
  summarize(Number_entries = length(USAFID),
            Number_NA_temp = sum(is.na(temp)),
            Number_stations = length(unique(USAFID)),
            Number_states = length(unique(STATE)),
            Mean_temp = mean(temp, na.rm = TRUE),
            Mean_windspeed = mean(wind.sp, na.rm = TRUE),
            Mean_atm = mean(atm.press, na.rm = TRUE))
Table


```

